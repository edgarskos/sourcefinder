#!/bin/bash

# sourcefinder script - 
# 1. takes a list of WD items known to have a given source (eg ODNB)
# 2. generates a list of all enWP article matches
# 3. looks to see if each of those matches has an appropriate link/template somewhere
# 4. if not, bing! puts it on a list
# 5. takes list from 4. and generates a pretty citation for it.

# step 0, initialise

# this should be run from within the /scripts directory

# cd ~/scripts # comment out for testing
#mkdir -p working
#rm working/*

# step 1 & 2

# curl -H "Accept: text/tab-separated-values" "https://query.wikidata.org/bigdata/namespace/wdq/sparql?query=PREFIX%20schema%3A%20%3Chttp%3A%2F%2Fschema.org%2F%3E%0APREFIX%20wikibase%3A%20%3Chttp%3A%2F%2Fwikiba.se%2Fontology%23%3E%0APREFIX%20wd%3A%20%3Chttp%3A%2F%2Fwww.wikidata.org%2Fentity%2F%3E%0APREFIX%20wdt%3A%20%3Chttp%3A%2F%2Fwww.wikidata.org%2Fprop%2Fdirect%2F%3E%0A%0ASELECT%20%3Fcid%20%3Fodnb%20%3Farticle%20WHERE%20%7B%0A%20%20%20%20%3Fcid%20wdt%3AP1415%20%3Fodnb%20.%0A%20%20%20%20OPTIONAL%20%7B%0A%20%20%20%20%20%20%3Farticle%20schema%3Aabout%20%3Fcid%20.%0A%20%20%20%20%20%20%3Farticle%20schema%3AinLanguage%20%22en%22%20.%0A%20%20%20%20%20%20%3Farticle%20schema%3AisPartOf%20%3Chttps%3A%2F%2Fen.wikipedia.org%2F%3E%20.%0A%20%20%20%20%7D%0A%7D%20" > working/odnb-sparql

# this file (which takes a couple of secs to generate) is a SPARQL query giving:
# COL 1 - Wikidata item URL
# COL 2 - ODNB number
# COL 3 - enwiki URL if this exists

grep "wikipedia.org" working/odnb-sparql | sed 's/<https\:\/\/en.wikipedia.org\/wiki\///' | sed 's/>//' | sed 's/<http\:\/\/www.wikidata.org\/entity\///' > working/odnb-trimmed

# trimmed.tsv now only has WP-matching lines - there's still 42000 of them! - and nicely tidied up

grep "wikipedia.org" working/odnb-sparql | tail -10 > working/odnb-trimmed

# for the purposes of testing replace it with a ten-line version

cut -f 3 working/odnb-trimmed > working/odnb-namelist

# so now we have
# working/odnb-trimmed - sample of "all articles matching an ODNB ID"
# working/odnb-namelist - just the page names from above

# now this next bit needs done because CURL IS AWFUL and keeps throwing weird exceptions about linebreaks?

COUNTER=`cat working/odnb-trimmed | wc -l`
rm working/template-logfile

for i in `seq 1 $COUNTER` ;
do QID=`sed "${i}q;d" working/odnb-trimmed | cut -f 2` ;
echo https://en.wikipedia.org/w/api.php?action=query\&prop=categories\&titles=`sed "${i}}q;d" working/namelist`\&cllimit=max\&format=json | tr -d $'\r' > working/slug
# this gives us the line we wish to curl with no linebreaks, thank god
if [ "`grep -v "Wikipedia articles incorporating a citation from the ODNB" working/catjson`" ] ;
then echo -e $QID"\t"NONE >> working/template-logfile ;
else echo -e $QID"\t"TEMP >> working/template-logfile ;
fi
done
# this very convoluted way of doing it is because, for some reason, curl does not like doing it any other way and keeps throwing errors

# step 3




# step 4



# step 5
